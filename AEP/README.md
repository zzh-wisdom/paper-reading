# 阅读笔记

## A Prompt Report on the Performance of Intel Optane DC Persistent Memory Module (2020)

堆AEP性能的一些补充，它测试方法和以往的不太一样，不显式flush cache，而是通过自动淘汰的方式写回。结论是：

1. 读写性能和DRAM仍有差距，读延迟是DRAM的3-4倍左右。带宽是DRAM的三分一；
2. 测试的写延迟比读延迟略高，大约391ns；
3. 单个AEP设备在4个线程左右性能最高，多个AEP interleave可以支持更好的线程扩展性。

## Basic performance measurements of the Intel Optane DC persistent memory module(2019)

对于 3D Xpoint Memory 比较全面的测试，报告长达 60 多页。

## Persistent memory I/O primitives(2019)

我们的 贡献可以总结为以下几点.

1. 我们提供了对英特尔Optane DC PMM的原生型的PMem的 首批分析之一.我们强调了PMem的物理特性对软件的影响 ,并得出了有效使用PMem的指导方针.
2. 我们介绍了一种持久化小数据块(事务性日志条目)的算法, 与最先进的算法相比,延迟降低了2倍.
3. 我们研究了将大数据块(数据库页面)以故障原子方式持久化到PMem的不同算法. 通过将写时复制方法与临时delta文件相结合,我们实现了显著的速度提升.

内存模式: 这种模式的优点是它对遗留 软件的工作是透明的,因此提供了一种以低成本扩展主内存容量的 简单方法.然而,这并不利用持久性,而且由于PMem的低带宽和 高延迟,性能可能会下降. 事实上,正如我们后面所显示的,当 DRAM作为L4缓存而不是通常情况下的L4缓存时,访问数据有 10%的开销.

提出了一个好的log技术。多计数器。和单次fence（类似校验和）

## An Empirical Guide to the Behavior and Use of Scalable Persistent Memory(fast20)

一些案例分析：

NOVA为每个元数据更新附加的日志条目很小--40-64B，由于NOVA使用了许多日志，日志更新表现出很少的位置性，特别是当文件系统处于负载状态时。解决方法是增加日志条目的大小，减少写放大。（启发：对比64B和256B对齐的效果）

数据显示，在每次64B的存储之后进行冲洗，可以提高大于64B的访问的带宽。我们认为出现这种情况是因为让缓存自然地驱逐缓存行，给到达Optane DIMM的访问流增加了非确定性。主动清理缓存可以确保访问保持顺序性。EWR与这一假设相关。增加冲刷会使EWR从0.26增加到0.98。

但我们的分析表明，如果微缓冲对小对象使用正常存储，只要在更新后立即刷新受影响的缓存行，其性能会更好。**图14比较了未修改的PMDK和微缓冲与基于非时序和正常存储的回写对不同大小的对象的无操作事务的延迟。微缓冲的正常存储和非时序存储之间的交叉点出现在1 kB处。**

